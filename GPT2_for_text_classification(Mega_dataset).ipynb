{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/amrtanair/master_thesis/blob/main/GPT2_for_text_classification(Mega_dataset).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wef16YiHfO9S",
        "outputId": "70ad8731-70ce-48cc-a515-173ef526ea73"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# from IPython.display import HTML, display\n",
        "\n",
        "# def set_css():\n",
        "#   display(HTML('''\n",
        "#   <style>\n",
        "#     pre {\n",
        "#         white-space: pre-wrap;\n",
        "#     }\n",
        "#   </style>\n",
        "#   '''))\n",
        "# get_ipython().events.register('pre_run_cell', set_css)\n",
        "\n",
        "# !pip uninstall transformers\n",
        "# !pip install transformers==4.35.2\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "JYyUXmSxRiwc"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import datetime\n",
        "import json\n",
        "import numpy as np\n",
        "import random\n",
        "import pandas as pd\n",
        "import torch\n",
        "import re\n",
        "import pickle\n",
        "import math\n",
        "import shutil\n",
        "\n",
        "from tqdm.notebook import tqdm\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "from transformers import (set_seed,\n",
        "                          GPT2Config,\n",
        "                          GPT2Tokenizer,\n",
        "                          GPT2ForSequenceClassification)\n",
        "\n",
        "from sklearn.metrics import matthews_corrcoef"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "Vm1GToa5Re86"
      },
      "outputs": [],
      "source": [
        "class AcceptabilityDataset(Dataset):\n",
        "  def __init__(self, texts, labels):\n",
        "    self.texts = texts\n",
        "    self.labels = labels\n",
        "    self.n_examples = len(self.labels)\n",
        "    return\n",
        "\n",
        "  def __len__(self):\n",
        "    return self.n_examples\n",
        "\n",
        "  def __getitem__(self, item):\n",
        "    return {'text':self.texts[item],\n",
        "            'label':self.labels[item]}\n",
        "\n",
        "\n",
        "class Collator(object):\n",
        "    def __init__(self, tokenizer, labels_encoder):\n",
        "        self.tokenizer = tokenizer\n",
        "        self.labels_encoder = labels_encoder\n",
        "        return\n",
        "\n",
        "    def __call__(self, sequences):\n",
        "        texts = [sequence['text'] for sequence in sequences]\n",
        "        labels = [sequence['label'] for sequence in sequences]\n",
        "        labels = [self.labels_encoder[label] for label in labels]\n",
        "        max_tokens = max([len(self.tokenizer.tokenize(text)) for text in texts])\n",
        "\n",
        "        inputs = self.tokenizer(text=texts, return_tensors=\"pt\", padding=True, truncation=True,  max_length=max_tokens)\n",
        "        inputs.update({'labels':torch.tensor(labels)})\n",
        "        return inputs\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "ktdua5LpalrI"
      },
      "outputs": [],
      "source": [
        "def train(dataloader, model, optimizer, device):\n",
        "\tpredictions_labels = []\n",
        "\ttrue_labels = []\n",
        "\ttotal_loss = 0\n",
        "\tmodel.train()\n",
        "\tfor batch in dataloader:\n",
        "\t\ttrue_labels += batch['labels'].numpy().flatten().tolist()\n",
        "\t\tbatch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n",
        "\t\tmodel.zero_grad()\n",
        "\t\toutputs = model(**batch)\n",
        "\t\tloss, logits = outputs[:2]\n",
        "\t\ttotal_loss += loss.item()\n",
        "\t\tloss.backward()\n",
        "\t\ttorch.nn.utils.clip_grad_norm_(model.parameters(), 1.0)\n",
        "\t\toptimizer.step()\n",
        "\t\tlogits = logits.detach().cpu().numpy()\n",
        "\t\tpredictions_labels += logits.argmax(axis=-1).flatten().tolist()\n",
        "\tavg_epoch_loss = total_loss / len(dataloader)\n",
        "\treturn model, true_labels, predictions_labels, avg_epoch_loss\n",
        "\n",
        "def validation(dataloader, model, device):\n",
        "\tpredictions_labels = []\n",
        "\ttrue_labels = []\n",
        "\ttotal_loss = 0\n",
        "\tmodel.eval()\n",
        "\tfor batch in dataloader:\n",
        "\t\ttrue_labels += batch['labels'].numpy().flatten().tolist()\n",
        "\t\tbatch = {k:v.type(torch.long).to(device) for k,v in batch.items()}\n",
        "\t\twith torch.no_grad():\n",
        "\t\t\toutputs = model(**batch)\n",
        "\t\t\tloss, logits = outputs[:2]\n",
        "\t\t\tlogits = logits.detach().cpu().numpy()\n",
        "\t\t\ttotal_loss += loss.item()\n",
        "\t\t\tpredict_content = logits.argmax(axis=-1).flatten().tolist()\n",
        "\t\t\tpredictions_labels += predict_content\n",
        "\tavg_epoch_loss = total_loss / len(dataloader)\n",
        "\treturn true_labels, predictions_labels, avg_epoch_loss\n",
        "\n",
        "def ranking_param(measure, logprob, unilp, sentence_len):\n",
        "    if measure == 'LogProb':\n",
        "        return logprob\n",
        "    elif measure == 'MeanLP':\n",
        "        return logprob/sentence_len\n",
        "    elif measure == 'NormLP_div':\n",
        "        return -(logprob/unilp)\n",
        "    elif measure == 'SLOR':\n",
        "        return (logprob - logprob)/sentence_len\n",
        "    elif measure == 'NormLP_sub':\n",
        "        return logprob-unilp\n",
        "    elif measure == 'Prob':\n",
        "        return\n",
        "\n",
        "def save_model(model, path):\n",
        "\tmodel.save_pretrained(path)\n",
        "\n",
        "def load_model(path):\n",
        "\tmodel = GPT2ForSequenceClassification.from_pretrained(path)\n",
        "\treturn model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "lrz7GjEHvT8R"
      },
      "outputs": [],
      "source": [
        "def run_model(device, model, tokenizer, measure):\n",
        "    unigram_freq = pickle.load(open('/content/drive/MyDrive/gpt-openwebtext.pickle', \"rb\"))\n",
        "    unigram_total = sum(unigram_freq.values())\n",
        "\n",
        "    input_file_path = '/content/drive/MyDrive/OIE2016_search_res.json'\n",
        "    with open(input_file_path, 'r') as file:\n",
        "        json_data = file.read()\n",
        "\n",
        "    data_dict = json.loads(json_data)\n",
        "    pattern = r'\\$input_txt:\\$ '\n",
        "\n",
        "    search_results = {}\n",
        "    sentences = {}\n",
        "\n",
        "    for key, value in data_dict.items():\n",
        "        sentence = re.sub(pattern, '', value[0][0])\n",
        "        sentences[key] = sentence\n",
        "        search_results[key] = []\n",
        "        for k, v in value[0][1][\"deduplicated:\"].items():\n",
        "            np_pair = [sentence[start:end] for start, end in v[2]]\n",
        "            triple_text =  np_pair[0] + ' [SEP] ' + k.split(' [SEP] ')[1] + ' [SEP] ' + np_pair[1]\n",
        "            search_results[key].append([triple_text, v[1]])\n",
        "\n",
        "    k = 4\n",
        "    print(\"Selecting top: \", k)\n",
        "    result_file = 'gpt2-finetuned-mega_' + 'tab_seperated_' + measure + '_' + str(k) + '.txt'\n",
        "\n",
        "    with open(result_file, \"w\") as f:\n",
        "        ID = 0\n",
        "        for key, value in tqdm(sentences.items()):\n",
        "            temp = []\n",
        "\n",
        "            triples = search_results[key]\n",
        "            for triple in triples:\n",
        "                input_text = triple[0].replace(\"[SEP] \", \"\")\n",
        "                input_id = tokenizer(input_text, return_tensors='pt')[\"input_ids\"].to(device)\n",
        "                tokenize_input = tokenizer.tokenize(input_text)\n",
        "                uni_lp = 0.0\n",
        "                # for w in tokenize_input:\n",
        "                #     uni_lp += math.log(float(unigram_freq[w])/unigram_total)\n",
        "                for w in tokenize_input:\n",
        "                    try:\n",
        "                        if unigram_freq[w] > 0 and unigram_total > 0:\n",
        "                            uni_lp += math.log(float(unigram_freq[w]) / unigram_total)\n",
        "                    except:\n",
        "                        print(triple)\n",
        "                output = model(input_id)\n",
        "                probabilities = torch.softmax(output.logits, dim=1)[0][1].item()\n",
        "                logprob = math.log(probabilities)\n",
        "                if measure == 'Prob':\n",
        "                    ranking_value = probabilities\n",
        "                else:\n",
        "                    ranking_value = ranking_param(measure, logprob, uni_lp, len(input_text))\n",
        "                temp.append([triple, ranking_value])\n",
        "\n",
        "            temp = sorted(temp, key=lambda x: x[1], reverse = True)[:k]\n",
        "            f.write(value+\"\\n\")\n",
        "\n",
        "            ID = ID + 1\n",
        "            for t in temp:\n",
        "                text = t[0][0].split(\"[SEP] \")\n",
        "                try:\n",
        "                    f.write(str(ID)+'\\t'+\n",
        "                     ('\"'+text[0]+'\"')+'\\t'+\n",
        "                      ('\"'+text[1]+'\"')+'\\t'+\n",
        "                       ('\"'+text[2]+'\"')+'\\t'+\n",
        "                            str(t[0][1])+ '\\n')\n",
        "                except:\n",
        "                    print(ID)\n",
        "\n",
        "    return result_file\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "id": "u2rVqJatRoYj",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000,
          "referenced_widgets": [
            "6d43861983f04164b17c25de8951d3d3",
            "d5e0b01a6bdc4d748f15f8e2102a5bc2",
            "e650c36e427c4bf7b79526c43e41c918",
            "fc83456b0df3464a9464d452b44cb4eb",
            "30f1ce114eda46c0b2de9157a4a3dd7d",
            "58cc2e9d75044912bad1164d3b6327ab",
            "9cbbf801b5ec4aba8f6e2af5b3891c28",
            "ce3715ee9a56491ca366a9f6d77daf20",
            "6ff0f0b4ce2e4f5da98f9f089e6bad9e",
            "64c7c946804d4f36acb335f8bf0a631a",
            "e5a78f4c36bb4c858444630371fe205d"
          ]
        },
        "outputId": "49baf6f2-3e1f-4c55-8e61-870e1a7155f3"
      },
      "outputs": [
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "GPU: Tesla T4\n",
            "Batch size:  124\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.10/dist-packages/huggingface_hub/file_download.py:1132: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Loading tokenizer...\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "6d43861983f04164b17c25de8951d3d3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "  0%|          | 0/10 [00:00<?, ?it/s]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Initializing model...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 1...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.57518 - val_loss: 0.44552 - train_acc: 0.70876 - valid_acc: 0.80289\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43486 - val_loss: 0.38356 - train_acc: 0.80384 - valid_acc: 0.83229\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.38922 - val_loss: 0.37457 - train_acc: 0.82588 - valid_acc: 0.83990\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36817 - val_loss: 0.35101 - train_acc: 0.83645 - valid_acc: 0.85233\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34842 - val_loss: 0.35366 - train_acc: 0.84603 - valid_acc: 0.84819\n",
            "Penalty applied\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33625 - val_loss: 0.35191 - train_acc: 0.85154 - valid_acc: 0.84926\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32629 - val_loss: 0.35019 - train_acc: 0.85628 - valid_acc: 0.85260\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31673 - val_loss: 0.34941 - train_acc: 0.86119 - valid_acc: 0.85113\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30598 - val_loss: 0.35248 - train_acc: 0.86703 - valid_acc: 0.85073\n",
            "Penalty applied\n",
            "Epoch:  10\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.29952 - val_loss: 0.34865 - train_acc: 0.86897 - valid_acc: 0.85300\n",
            "For fold 1, MCC is 0.7020364978343702, validation accuracy 0.8530001336362422\n",
            "Saving model to:  ./GPT2-model/\n",
            "Initializing model...\n"
          ]
        },
        {
          "metadata": {
            "tags": null
          },
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 2...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.57505 - val_loss: 0.44420 - train_acc: 0.70617 - valid_acc: 0.79941\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43950 - val_loss: 0.38272 - train_acc: 0.80218 - valid_acc: 0.83001\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.39501 - val_loss: 0.37312 - train_acc: 0.82355 - valid_acc: 0.83282\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.37043 - val_loss: 0.36298 - train_acc: 0.83544 - valid_acc: 0.84218\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.35208 - val_loss: 0.35492 - train_acc: 0.84542 - valid_acc: 0.84618\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34117 - val_loss: 0.35749 - train_acc: 0.84872 - valid_acc: 0.84431\n",
            "Penalty applied\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32889 - val_loss: 0.35582 - train_acc: 0.85516 - valid_acc: 0.84431\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32011 - val_loss: 0.35086 - train_acc: 0.85982 - valid_acc: 0.85019\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31123 - val_loss: 0.36869 - train_acc: 0.86337 - valid_acc: 0.84578\n",
            "Penalty applied\n",
            "Epoch:  10\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30296 - val_loss: 0.35911 - train_acc: 0.86726 - valid_acc: 0.84739\n",
            "For fold 2, MCC is 0.6944634072668681, validation accuracy 0.8473874114659896\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 3...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.57924 - val_loss: 0.45667 - train_acc: 0.69391 - valid_acc: 0.79687\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.44225 - val_loss: 0.41214 - train_acc: 0.79905 - valid_acc: 0.82400\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.39778 - val_loss: 0.38268 - train_acc: 0.82251 - valid_acc: 0.83777\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.37239 - val_loss: 0.37590 - train_acc: 0.83519 - valid_acc: 0.84271\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.35511 - val_loss: 0.37043 - train_acc: 0.84230 - valid_acc: 0.84271\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34208 - val_loss: 0.36294 - train_acc: 0.84821 - valid_acc: 0.84672\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32995 - val_loss: 0.35822 - train_acc: 0.85472 - valid_acc: 0.84659\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32051 - val_loss: 0.36783 - train_acc: 0.85877 - valid_acc: 0.83857\n",
            "Penalty applied\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31020 - val_loss: 0.36905 - train_acc: 0.86440 - valid_acc: 0.84324\n",
            "Penalty applied\n",
            "Epoch:  10\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30278 - val_loss: 0.37159 - train_acc: 0.86756 - valid_acc: 0.84632\n",
            "For fold 3, MCC is 0.6901516446581912, validation accuracy 0.8463183215287986\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 4...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.59589 - val_loss: 0.46057 - train_acc: 0.70646 - valid_acc: 0.79914\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.44107 - val_loss: 0.39118 - train_acc: 0.80026 - valid_acc: 0.82601\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.39300 - val_loss: 0.36982 - train_acc: 0.82386 - valid_acc: 0.83576\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36820 - val_loss: 0.38375 - train_acc: 0.83899 - valid_acc: 0.83950\n",
            "Penalty applied\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.35326 - val_loss: 0.36021 - train_acc: 0.84411 - valid_acc: 0.84792\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33815 - val_loss: 0.35854 - train_acc: 0.85093 - valid_acc: 0.84645\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32533 - val_loss: 0.35784 - train_acc: 0.85613 - valid_acc: 0.84391\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31597 - val_loss: 0.36407 - train_acc: 0.86092 - valid_acc: 0.84592\n",
            "Penalty applied\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30606 - val_loss: 0.37476 - train_acc: 0.86496 - valid_acc: 0.84645\n",
            "For fold 4, MCC is 0.6940985220704247, validation accuracy 0.8464519577709475\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 5...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.60237 - val_loss: 0.46181 - train_acc: 0.69573 - valid_acc: 0.79540\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43663 - val_loss: 0.39170 - train_acc: 0.80387 - valid_acc: 0.82560\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.38791 - val_loss: 0.37603 - train_acc: 0.82769 - valid_acc: 0.83750\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36300 - val_loss: 0.36523 - train_acc: 0.83875 - valid_acc: 0.84365\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34804 - val_loss: 0.35606 - train_acc: 0.84683 - valid_acc: 0.84765\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33381 - val_loss: 0.36400 - train_acc: 0.85236 - valid_acc: 0.84699\n",
            "Penalty applied\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32166 - val_loss: 0.34864 - train_acc: 0.85889 - valid_acc: 0.85086\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31272 - val_loss: 0.36293 - train_acc: 0.86314 - valid_acc: 0.84819\n",
            "Penalty applied\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30245 - val_loss: 0.35752 - train_acc: 0.86720 - valid_acc: 0.85327\n",
            "For fold 5, MCC is 0.7051796253371063, validation accuracy 0.8532674061205399\n",
            "Saving model to:  ./GPT2-model/\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 6...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.58420 - val_loss: 0.44844 - train_acc: 0.70805 - valid_acc: 0.80155\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43896 - val_loss: 0.37904 - train_acc: 0.80203 - valid_acc: 0.83242\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.39079 - val_loss: 0.36083 - train_acc: 0.82523 - valid_acc: 0.84204\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36611 - val_loss: 0.35834 - train_acc: 0.83777 - valid_acc: 0.84659\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.35044 - val_loss: 0.34903 - train_acc: 0.84613 - valid_acc: 0.85100\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33624 - val_loss: 0.35406 - train_acc: 0.85133 - valid_acc: 0.85100\n",
            "Penalty applied\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32609 - val_loss: 0.35786 - train_acc: 0.85657 - valid_acc: 0.84926\n",
            "Penalty applied\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31467 - val_loss: 0.35158 - train_acc: 0.86152 - valid_acc: 0.84912\n",
            "For fold 6, MCC is 0.6943801457177738, validation accuracy 0.8491246826139249\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 7...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.59012 - val_loss: 0.48294 - train_acc: 0.69230 - valid_acc: 0.78378\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43186 - val_loss: 0.40344 - train_acc: 0.80634 - valid_acc: 0.81932\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.38550 - val_loss: 0.38701 - train_acc: 0.82864 - valid_acc: 0.83295\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36193 - val_loss: 0.38806 - train_acc: 0.84025 - valid_acc: 0.82788\n",
            "Penalty applied\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34330 - val_loss: 0.36436 - train_acc: 0.84903 - valid_acc: 0.84151\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33096 - val_loss: 0.37962 - train_acc: 0.85405 - valid_acc: 0.83523\n",
            "Penalty applied\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31908 - val_loss: 0.37308 - train_acc: 0.86076 - valid_acc: 0.83803\n",
            "For fold 7, MCC is 0.6772357311714475, validation accuracy 0.8380328745155686\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 8...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.59657 - val_loss: 0.46265 - train_acc: 0.70492 - valid_acc: 0.79591\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43900 - val_loss: 0.37732 - train_acc: 0.80104 - valid_acc: 0.83360\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.39121 - val_loss: 0.37300 - train_acc: 0.82740 - valid_acc: 0.83855\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36739 - val_loss: 0.34993 - train_acc: 0.83737 - valid_acc: 0.84550\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34957 - val_loss: 0.34958 - train_acc: 0.84570 - valid_acc: 0.84563\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33777 - val_loss: 0.35845 - train_acc: 0.85124 - valid_acc: 0.84496\n",
            "Penalty applied\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32504 - val_loss: 0.34592 - train_acc: 0.85836 - valid_acc: 0.84884\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31630 - val_loss: 0.35281 - train_acc: 0.86052 - valid_acc: 0.84884\n",
            "Penalty applied\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30443 - val_loss: 0.37518 - train_acc: 0.86718 - valid_acc: 0.84362\n",
            "For fold 8, MCC is 0.691214396321791, validation accuracy 0.8436246992782679\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 9...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.55943 - val_loss: 0.42415 - train_acc: 0.71607 - valid_acc: 0.81409\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.42433 - val_loss: 0.38568 - train_acc: 0.80722 - valid_acc: 0.83307\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.38117 - val_loss: 0.37534 - train_acc: 0.83074 - valid_acc: 0.83895\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.35719 - val_loss: 0.36238 - train_acc: 0.84137 - valid_acc: 0.84149\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34321 - val_loss: 0.36889 - train_acc: 0.84902 - valid_acc: 0.84269\n",
            "Penalty applied\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33060 - val_loss: 0.37327 - train_acc: 0.85331 - valid_acc: 0.84496\n",
            "Penalty applied\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32098 - val_loss: 0.37463 - train_acc: 0.85911 - valid_acc: 0.84349\n",
            "For fold 9, MCC is 0.6860207925346035, validation accuracy 0.8434910451750869\n",
            "Initializing model...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Some weights of GPT2ForSequenceClassification were not initialized from the model checkpoint at gpt2 and are newly initialized: ['score.weight']\n",
            "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model loaded to  cuda\n",
            "Fold 10...\n",
            "Created train and validation splits.\n",
            "Epoch:  1\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.57854 - val_loss: 0.43375 - train_acc: 0.70724 - valid_acc: 0.80954\n",
            "Epoch:  2\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.43362 - val_loss: 0.37338 - train_acc: 0.80386 - valid_acc: 0.84015\n",
            "Epoch:  3\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.38863 - val_loss: 0.35032 - train_acc: 0.82667 - valid_acc: 0.84469\n",
            "Epoch:  4\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.36343 - val_loss: 0.35456 - train_acc: 0.83870 - valid_acc: 0.84456\n",
            "Penalty applied\n",
            "Epoch:  5\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.34795 - val_loss: 0.35423 - train_acc: 0.84630 - valid_acc: 0.84697\n",
            "Epoch:  6\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.33434 - val_loss: 0.35418 - train_acc: 0.85258 - valid_acc: 0.84991\n",
            "Epoch:  7\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.32412 - val_loss: 0.34935 - train_acc: 0.85739 - valid_acc: 0.84857\n",
            "Epoch:  8\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.31341 - val_loss: 0.35274 - train_acc: 0.86263 - valid_acc: 0.85044\n",
            "Penalty applied\n",
            "Epoch:  9\n",
            "Training on batches...\n",
            "Validation on batches...\n",
            "  train_loss: 0.30434 - val_loss: 0.36970 - train_acc: 0.86685 - valid_acc: 0.84483\n",
            "For fold 10, MCC is 0.6883445638184998, validation accuracy 0.8448275862068966\n",
            "{'fold': [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], 'mcc': [0.7020364978343702, 0.6944634072668681, 0.6901516446581912, 0.6940985220704247, 0.7051796253371063, 0.6943801457177738, 0.6772357311714475, 0.691214396321791, 0.6860207925346035, 0.6883445638184998], 'val_acc': [0.8530001336362422, 0.8473874114659896, 0.8463183215287986, 0.8464519577709475, 0.8532674061205399, 0.8491246826139249, 0.8380328745155686, 0.8436246992782679, 0.8434910451750869, 0.8448275862068966], 'epochs': [11, 11, 11, 10, 10, 9, 8, 10, 8, 10]}\n"
          ]
        }
      ],
      "source": [
        "if __name__ == \"__main__\":\n",
        "\tseed = 2024\n",
        "\trandom.seed(seed)\n",
        "\tnp.random.seed(seed)\n",
        "\ttorch.manual_seed(seed)\n",
        "\n",
        "\tif torch.cuda.is_available():\n",
        "\t\ttorch.cuda.manual_seed_all(seed)\n",
        "\t\tdevice = torch.device(\"cuda\")\n",
        "\t\tdevice_name = torch.cuda.get_device_name(0)\n",
        "\t\tprint('GPU:', device_name)\n",
        "\telse:\n",
        "\t\tprint('Using CPU')\n",
        "\t\tdevice = torch.device(\"cpu\")\n",
        "\t\tdevice_name = 'cpu'\n",
        "\n",
        "\tif not os.path.exists('/content/drive/MyDrive/thesis/models/GPT2-model'):\n",
        "\t\tbatch_size = 124\n",
        "\t\tmodel_name = 'gpt2'\n",
        "\t\tlr = 2e-05\n",
        "\t\tlabels_ids = {'0': 0, '1': 1}\n",
        "\t\tn_labels = len(labels_ids)\n",
        "\t\tprint(\"Batch size: \", batch_size)\n",
        "\n",
        "\t\tconfig = GPT2Config.from_pretrained(model_name, activation_function = \"gelu\", attn_pdrop = 0.15,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\tnum_labels=n_labels)\n",
        "\n",
        "\t\tprint('Loading tokenizer...')\n",
        "\t\ttokenizer = GPT2Tokenizer.from_pretrained(model_name)\n",
        "\t\ttokenizer.padding_side = \"left\"\n",
        "\t\ttokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\t\tdataset_collator = Collator(tokenizer = tokenizer, labels_encoder = labels_ids)\n",
        "\n",
        "\t\tpath = '/content/drive/MyDrive/thesis/mega_acceptability.tsv'\n",
        "\t\tdf = pd.read_csv(path,\n",
        "\t\t                 delimiter='\\t',\n",
        "\t\t\t\t\t\t\t\t\t\theader=None,\n",
        "\t\t\t\t\t\t\t\t\t\tnames=['sentence_source', 'label', 'label_notes', 'sentence'])\n",
        "\t\ttexts = df.sentence.values\n",
        "\t\tdf['label'] = df['label'].astype(str)\n",
        "\t\tlabels = df.label.values\n",
        "\n",
        "\t\tkf = KFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\t\tbest_mcc = 0\n",
        "\t\tresults = {'fold': [], 'mcc': [], 'val_acc': [], 'epochs': []}\n",
        "\n",
        "\t\tfor fold, (train_index, val_index) in enumerate(tqdm(kf.split(texts), total=kf.n_splits)):\n",
        "\t\t\tprint('Initializing model...')\n",
        "\t\t\tmodel = GPT2ForSequenceClassification.from_pretrained(model_name, config = config)\n",
        "\t\t\tmodel.config.pad_token_id = model.config.eos_token_id\n",
        "\t\t\tmodel.to(device)\n",
        "\t\t\tprint('Model loaded to ', device)\n",
        "\n",
        "\t\t\tprint(f'Fold {fold + 1}...')\n",
        "\t\t\ttrain_texts, val_texts = texts[train_index], texts[val_index]\n",
        "\t\t\ttrain_labels, val_labels = labels[train_index], labels[val_index]\n",
        "\n",
        "\t\t\ttrain_dataset = AcceptabilityDataset(train_texts, train_labels)\n",
        "\t\t\tval_dataset = AcceptabilityDataset(val_texts, val_labels)\n",
        "\n",
        "\t\t\ttrain_dataloader = DataLoader(train_dataset,\n",
        "\t\t\t                              batch_size=batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle=True,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcollate_fn=dataset_collator)\n",
        "\t\t\tval_dataloader = DataLoader(val_dataset,\n",
        "\t\t\t                            batch_size=batch_size,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tshuffle=False,\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\t\tcollate_fn=dataset_collator)\n",
        "\n",
        "\t\t\tprint(f'Created train and validation splits.')\n",
        "\n",
        "\t\t\toptimizer = torch.optim.Adam(model.parameters(),\n",
        "\t\t\t\t\t\t\t\t\tlr = lr,\n",
        "\t\t\t\t\t\t\t\t\teps = 1e-08)\n",
        "\n",
        "\t\t\tall_loss = {'train_loss':[], 'val_loss':[]}\n",
        "\t\t\tall_acc = {'train_acc':[], 'val_acc':[]}\n",
        "\n",
        "\t\t\tcurr_val_loss = None\n",
        "\t\t\tprev_val_loss = None\n",
        "\t\t\tepoch = 1\n",
        "\t\t\tpenalty = 0\n",
        "\n",
        "\t\t\t#dynamic early stopping based on validation loss\n",
        "\t\t\twhile True:\n",
        "\t\t\t\tprint(\"Epoch: \", epoch)\n",
        "\t\t\t\tepoch = epoch + 1\n",
        "\t\t\t\tprint('Training on batches...')\n",
        "\t\t\t\tmodel, train_labels, train_predict, train_loss = train(train_dataloader, model, optimizer, device)\n",
        "\t\t\t\ttrain_acc = accuracy_score(train_labels, train_predict)\n",
        "\t\t\t\tprint('Validation on batches...')\n",
        "\t\t\t\tvalid_labels, valid_predict, val_loss = validation(val_dataloader, model, device)\n",
        "\t\t\t\tval_acc = accuracy_score(valid_labels, valid_predict)\n",
        "\t\t\t\tprev_val_loss = curr_val_loss\n",
        "\t\t\t\tcurr_val_loss = val_loss\n",
        "\t\t\t\tprint(\"  train_loss: %.5f - val_loss: %.5f - train_acc: %.5f - valid_acc: %.5f\"%(train_loss, val_loss, train_acc, val_acc))\n",
        "\n",
        "\t\t\t\tif curr_val_loss is not None and prev_val_loss is not None:\n",
        "\t\t\t\t\tif penalty > 1:\n",
        "\t\t\t\t\t\tbreak\n",
        "\t\t\t\t\tif curr_val_loss > prev_val_loss:\n",
        "\t\t\t\t\t\tpenalty = penalty + 1\n",
        "\t\t\t\t\t\tprint(\"Penalty applied\")\n",
        "\t\t\t\tall_loss['train_loss'].append(train_loss)\n",
        "\t\t\t\tall_loss['val_loss'].append(val_loss)\n",
        "\t\t\t\tall_acc['train_acc'].append(train_acc)\n",
        "\t\t\t\tall_acc['val_acc'].append(val_acc)\n",
        "\n",
        "\t\t\tmcc = matthews_corrcoef(valid_labels, valid_predict)\n",
        "\t\t\tprint(f'For fold {fold + 1}, MCC is {mcc}, validation accuracy {val_acc}')\n",
        "\n",
        "\t\t\tresults['fold'].append(fold+1)\n",
        "\t\t\tresults['mcc'].append(mcc)\n",
        "\t\t\tresults['val_acc'].append(val_acc)\n",
        "\t\t\tresults['epochs'].append(epoch)\n",
        "\n",
        "\t\t\tif best_mcc < mcc:\n",
        "\t\t\t\tbest_mcc = mcc\n",
        "\t\t\t\toutput_dir = './GPT2-model/'\n",
        "\t\t\t\tif os.path.exists(output_dir):\n",
        "\t\t\t\t\t\tshutil.rmtree(output_dir)\n",
        "\n",
        "\t\t\t\ttraining_args = {'created': datetime.datetime.now().strftime('%d_%m_%Y_%H_%M_%S'),\n",
        "\t\t\t\t\t\t\t\t'model': model_name,\n",
        "\t\t\t\t\t\t\t\t'device': device_name,\n",
        "\t\t\t\t\t\t\t\t'batch_size': batch_size,\n",
        "\t\t\t\t\t\t\t\t'epochs': epoch,\n",
        "\t\t\t\t\t\t\t\t'learning_rate': lr,\n",
        "\t\t\t\t\t\t\t\t'optimizer': type(optimizer).__name__,\n",
        "\t\t\t\t\t\t\t\t'seed': seed,\n",
        "\t\t\t\t\t\t\t\t'MCC': mcc,\n",
        "\t\t\t\t\t\t\t\t'accuracy': val_acc,\n",
        "\t\t\t\t\t\t\t\t}\n",
        "\t\t\t\tos.makedirs(output_dir)\n",
        "\t\t\t\tprint(\"Saving model to: \", output_dir)\n",
        "\t\t\t\tsave_model(model, output_dir)\n",
        "\n",
        "\t\t\t\twith open(output_dir + '/training_args.json', \"w\") as json_file:\n",
        "\t\t\t\t\tjson.dump(training_args, json_file)\n",
        "\t\t\t\twith open(output_dir + '/all_loss.json', \"w\") as json_file:\n",
        "\t\t\t\t\tjson.dump(all_loss, json_file)\n",
        "\t\t\t\twith open(output_dir + '/all_acc.json', \"w\") as json_file:\n",
        "\t\t\t\t\tjson.dump(all_acc, json_file)\n",
        "\n",
        "\t\tprint(results)\n",
        "\telse:\n",
        "\t\tprint(\"Model is present, creating evaluation file for different normalization schemes.\")\n",
        "\t\tprint(\"Loading model...\")\n",
        "\t\tmodel = load_model('/content/drive/MyDrive/models/GPT2-model')\n",
        "\t\tmodel.to(device)\n",
        "\n",
        "\t\tprint('Loading tokenizer...')\n",
        "\t\ttokenizer = GPT2Tokenizer.from_pretrained('gpt2')\n",
        "\t\ttokenizer.padding_side = \"left\"\n",
        "\t\ttokenizer.pad_token = tokenizer.eos_token\n",
        "\n",
        "\t# measures = ['NormLP_sub','LogProb', 'MeanLP', 'NormLP_div', 'SLOR', 'Prob']\n",
        "\t# for measure in measures:\n",
        "\t# \tprint(\"The measure being used is: \", measure)\n",
        "\t# \tfile_path = run_model(device, model, tokenizer, measure)\n",
        "\t# \tprint(\"Linguistic Acceptability Model Result saved at: \", file_path)\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "Ph2QKN5_GihR"
      },
      "outputs": [],
      "source": [
        "!cp -r /content/GPT2-model/ /content/drive/MyDrive/thesis/models/gpt2_MA_seed2024"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "kS0-KtUwRZ9z"
      }
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "gpuType": "T4",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    },
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "6d43861983f04164b17c25de8951d3d3": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HBoxModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HBoxView",
            "box_style": "",
            "children": [
              "IPY_MODEL_d5e0b01a6bdc4d748f15f8e2102a5bc2",
              "IPY_MODEL_e650c36e427c4bf7b79526c43e41c918",
              "IPY_MODEL_fc83456b0df3464a9464d452b44cb4eb"
            ],
            "layout": "IPY_MODEL_30f1ce114eda46c0b2de9157a4a3dd7d"
          }
        },
        "d5e0b01a6bdc4d748f15f8e2102a5bc2": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_58cc2e9d75044912bad1164d3b6327ab",
            "placeholder": "",
            "style": "IPY_MODEL_9cbbf801b5ec4aba8f6e2af5b3891c28",
            "value": "100%"
          }
        },
        "e650c36e427c4bf7b79526c43e41c918": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "FloatProgressModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "ProgressView",
            "bar_style": "success",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_ce3715ee9a56491ca366a9f6d77daf20",
            "max": 10,
            "min": 0,
            "orientation": "horizontal",
            "style": "IPY_MODEL_6ff0f0b4ce2e4f5da98f9f089e6bad9e",
            "value": 10
          }
        },
        "fc83456b0df3464a9464d452b44cb4eb": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "model_module_version": "1.5.0",
          "state": {
            "_dom_classes": [],
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "HTMLModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/controls",
            "_view_module_version": "1.5.0",
            "_view_name": "HTMLView",
            "description": "",
            "description_tooltip": null,
            "layout": "IPY_MODEL_64c7c946804d4f36acb335f8bf0a631a",
            "placeholder": "",
            "style": "IPY_MODEL_e5a78f4c36bb4c858444630371fe205d",
            "value": "10/10[3:30:23&lt;00:00,1194.46s/it]"
          }
        },
        "30f1ce114eda46c0b2de9157a4a3dd7d": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "58cc2e9d75044912bad1164d3b6327ab": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "9cbbf801b5ec4aba8f6e2af5b3891c28": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        },
        "ce3715ee9a56491ca366a9f6d77daf20": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "6ff0f0b4ce2e4f5da98f9f089e6bad9e": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "ProgressStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "bar_color": null,
            "description_width": ""
          }
        },
        "64c7c946804d4f36acb335f8bf0a631a": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "model_module_version": "1.2.0",
          "state": {
            "_model_module": "@jupyter-widgets/base",
            "_model_module_version": "1.2.0",
            "_model_name": "LayoutModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "LayoutView",
            "align_content": null,
            "align_items": null,
            "align_self": null,
            "border": null,
            "bottom": null,
            "display": null,
            "flex": null,
            "flex_flow": null,
            "grid_area": null,
            "grid_auto_columns": null,
            "grid_auto_flow": null,
            "grid_auto_rows": null,
            "grid_column": null,
            "grid_gap": null,
            "grid_row": null,
            "grid_template_areas": null,
            "grid_template_columns": null,
            "grid_template_rows": null,
            "height": null,
            "justify_content": null,
            "justify_items": null,
            "left": null,
            "margin": null,
            "max_height": null,
            "max_width": null,
            "min_height": null,
            "min_width": null,
            "object_fit": null,
            "object_position": null,
            "order": null,
            "overflow": null,
            "overflow_x": null,
            "overflow_y": null,
            "padding": null,
            "right": null,
            "top": null,
            "visibility": null,
            "width": null
          }
        },
        "e5a78f4c36bb4c858444630371fe205d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "model_module_version": "1.5.0",
          "state": {
            "_model_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_model_name": "DescriptionStyleModel",
            "_view_count": null,
            "_view_module": "@jupyter-widgets/base",
            "_view_module_version": "1.2.0",
            "_view_name": "StyleView",
            "description_width": ""
          }
        }
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}